{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trabalho 1 RP36O 2020/2 (UTFPR)\n",
    "## Autores: Rafael Rampim Soratto e Venancius\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dependencias:\n",
    "```shell\n",
    "pip install -r ./requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "import numpy\n",
    "import json\n",
    "import mne\n",
    "import matplotlib\n",
    "from scipy.signal import stft\n",
    "import scipy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparação do dataset do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloco de declaração dos identificadores de download (google drive) e setup\n",
    "dataset_ids = {\n",
    "    1: '1ym3JqI4_ZYNSBLxoF1vNxI5Hsgur_tha',\n",
    "    2: '1tJ5tHbE-2jwr0gA33Gd873lRPao-e4dF',\n",
    "    3: '1tXdpY-mser01POaP6Qwixny6LjsXXoXB',\n",
    "    4: '1T00cliWp5yqqbbWZ7-rf2X4tOUQ-PvIQ',\n",
    "    5: '1CYsBFMul9zB_vCy0XD7XVfKUl8vihDYZ',\n",
    "    6: '1io6jdALBKeopELWXahPzuAi6EfYDgviW',\n",
    "    7: '1YDkheRDPNDR1ujsqqC_SY6cebWHkw9Xt',\n",
    "    8: '1jjoQJFDCi7O9Q-iaReAPpQnxC-HIKpQi',\n",
    "}\n",
    "label_id = '1mD5MXoh6tfQJFXIvdw2MQsEu6vZka6C0'\n",
    "desc = '14kYNBZYdttqmSS_Vz6Bm_ztG9Uw1MC0y'\n",
    "DS = 6 #dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "gdd.download_file_from_google_drive(file_id=dataset_ids[DS],\n",
    "                                    dest_path='files/data.npy',\n",
    "                                    showsize=True)\n",
    "# download do arquivo de marcações\n",
    "gdd.download_file_from_google_drive(file_id=label_id,\n",
    "                                    dest_path='files/labels.npy', showsize=True)\n",
    "\n",
    "# download do arquivo de descrição\n",
    "gdd.download_file_from_google_drive(file_id=desc,\n",
    "                                    dest_path='files/descriptor.json',\n",
    "                                    showsize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.load('files/data.npy')\n",
    "y = numpy.load('files/labels.npy')\n",
    "desc_file = open('files/descriptor.json')\n",
    "descriptor = json.loads(desc_file.read())\n",
    "desc_file.close()\n",
    "print('Estruturas => dados', X.shape, 'labels', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estrutura \n",
    "\n",
    "Os dados estão estruturados em numpy arrays.\n",
    "\n",
    "# Shape\n",
    "O \"shape\" (125, 257, 1205) para os dados EEG de X, significa que existem 125 trials (tradução aceitável: ensaio, julgamento), 257 channels que representam os eletrodos e 1205 dados que representam o potencial mensurado em ponto flutuante. Este é um array com três dimensões.\n",
    "\n",
    "O \"shape\" (125,) para os dados de labels ou marcadores y, apresentam qual é o eletrodo respectivo a cada trial. Os labels estão com valores numéricos como é mostrado a seguir, o que facilita o processamento, mas não é intuitivo.\n",
    "\n",
    "Desta forma, foi preparado um arquivo de descrição no qual é possível saber qual é o rótulo correto do correspondente \"número\", além de outras informações como a taxa de amostragem (sampling rate), idade, tipo do cabelo (curto, médio ou comprido), sexo, tamanho da touca e se é destro ou canhoto. A princípio, imaginamos que estas informações não são tão importantes, mas problemas na experimentação podem ter culpa por um desses motivos, como por exemplo, o tamanho do cabelo. Veja os dados do voluntário escolhido:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Características do voluntário:', descriptor[str(DS)])\n",
    "print('\\nRótulos:', descriptor['frequencies'])\n",
    "print('\\nTaxa de amostragem:', descriptor['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atributos\n",
    "Como é possível visualizar as características do voluntário são:\n",
    "```json\n",
    "{\n",
    "    idade: 31,\n",
    "    tamanho_cabeca: Médio,\n",
    "    gênero: Mulher,\n",
    "    tipo_cabelo: Grosso,\n",
    "    lateralidade: destro,\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling rate\n",
    "Os dados dos voluntários do trabalho não estão balanceados em número, portanto deve-se re-calcular a taxa de amostragem para utilizar vetores não esparsos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quantidade_de_dados / tempo_do_trial\n",
    "descriptor['sampling_rate'] = X.shape[-1] / 5\n",
    "sfreq = descriptor['sampling_rate']\n",
    "\n",
    "X = X[:,:256,:]\n",
    "ch_names = X.shape[1]\n",
    "ch_types = 'eeg'\n",
    "\n",
    "# objeto com o nome dos canais pelo modelo da touca utilizada\n",
    "montage = mne.channels.make_standard_montage('EGI_256')\n",
    "\n",
    "info = mne.create_info(montage.ch_names, sfreq, ch_types)\n",
    "info.set_montage(montage)\n",
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events = [[i, 0, e] for i, e in enumerate(y)]\n",
    "obj = mne.EpochsArray(X, info, events=numpy.array(events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtragem CAR \n",
    "Consiste na subtração ponto a ponto do sinal coletado em um dos eletrodos pela média pontual dos sinais coletados pelos 16 eletrodos. Na filtragem CAR considera-se que a média de todos os eletrodos é uma estimativa da atividade elétrica no eletrodo de referência, e essa atividade elétrica afeta igualmente as gravações de todos os outros eletrodos.\n",
    "\n",
    "Quando um ruído afeta a atividade elétrica coletada em todos os eletrodos, sendo esses eletrodos uniformemente espaçados por todo o córtex cerebral, esse ruído provavelmente é oriundo de alguma mudança na atividade elétrica do eletrodo de referência. Calculando-se a média dos sinais coletados\n",
    "em todos os 16 eletrodos, um novo sinal é encontrado e esse novo sinal é transformado na referência. O sinal coletado por cada eletrodo é então subtraído pelo novo sinal de referência, retirando aquilo que é comum a todos eles. Quando o número de eletrodos utilizados na coleta dos dados é igual ou maior que 16, sendo esses eletrodos uniformemente espaçados na cabeça, a abordagem CAR leva a uma filtragem do sinal EEG quase ideal (GARCIA-MOLINA; ZHU, 2011).\n",
    "\n",
    "Referências\n",
    "\n",
    "https://pdfs.semanticscholar.org/cb26/23303f2b647a15f8332877d574eb75690342.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleciona eletrodos\n",
    "selected_electrodes = ['E115', 'E116', 'E122', 'E123', 'E124', 'E125','E135', 'E137', 'E138', 'E149', 'E150', 'E157','E158', 'E159', 'E167', 'E147']\n",
    "epoch_ex = obj.copy().pick_channels(selected_electrodes)\n",
    "epoch_ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Epoch array')\n",
    "print(obj.get_data().shape)\n",
    "print('Epoch array filtrando eletrodos')\n",
    "print(epoch_ex.get_data().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_ex.save('files/unfiltered_epo.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Etapa de Pre processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [8., 6.]\n",
    "\n",
    "e = '1'\n",
    "\n",
    "trial = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o epoch sem filtros\n",
    "epochs = mne.read_epochs('files/unfiltered_epo.fif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados sem nenhum filtro, é possível observar o pico próximo a frequencia 50hz causado pela rede eletrica\n",
    "epochs[e][trial].plot_psd()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove frenquencias abaixo de 4hz e acima de 14hz\n",
    "epochs.filter(l_freq=4.0, h_freq=14.0)\n",
    "epochs[e][trial].plot_psd()\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafico apenas das frequencias de interesse (de 4hz até 14hz)\n",
    "epochs[e][trial].plot_psd(fmin=4.0, fmax=14.0)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epo_ref = mne.set_eeg_reference(epochs, ref_channels=['E116', 'E125', 'E138'])\n",
    "epochs = epo_ref[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs[e][15].plot_psd(fmin=4.0, fmax=14.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs.save('files/filtered_epo.fif', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set_eeg_reference METHOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "epochs = mne.read_epochs('files/filtered_epo.fif')\n",
    "data = epochs.get_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_welch_12 = epochs.copy()\n",
    "epoch_welch_12.filter(l_freq=11., h_freq=13.)\n",
    "epoch_welch_10 = epochs.copy()\n",
    "epoch_welch_10.filter(l_freq=9., h_freq=11.)\n",
    "epoch_welch_8_57 = epochs.copy()\n",
    "epoch_welch_8_57.filter(l_freq=8., h_freq=9.)\n",
    "epoch_welch_7_50 = epochs.copy()\n",
    "epoch_welch_7_50.filter(l_freq=7.1, h_freq=7.9)\n",
    "epoch_welch_6_66 = epochs.copy()\n",
    "epoch_welch_6_66.filter(l_freq=6.33, h_freq=7.)\n",
    "\n",
    "epoch_array = [epoch_welch_12, epoch_welch_10, epoch_welch_8_57, epoch_welch_7_50, epoch_welch_6_66]\n",
    "\n",
    "welch_array = []\n",
    "for i in range(len(epoch_array)):\n",
    "    epoch_welch, freqs = mne.time_frequency.psd_welch(epochs, n_per_seg=32, n_overlap=16)\n",
    "    freqs, epoch_welch = scipy.signal.welch(epoch_welch, fs=241, nperseg=32, noverlap=16)\n",
    "    w = numpy.abs(epoch_welch) ** 2\n",
    "\n",
    "    W = w\n",
    "    w.shape\n",
    "    welch_array.append(W)\n",
    "    print(w.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Média"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_array = []\n",
    "for i in range(len(welch_array)):\n",
    "    fmn = numpy.mean(W, axis=-1)\n",
    "    print('FMN:', fmn.shape)\n",
    "\n",
    "    # Max - 2*\n",
    "    mx = numpy.amax(W, axis=-1)\n",
    "    print('MAX:', mx.shape)\n",
    "\n",
    "    # Min - 3*\n",
    "    mn = numpy.amin(W, axis=-1)\n",
    "    print('MIN:', mn.shape)\n",
    "\n",
    "    # Standard deviation (SD) - 4*\n",
    "    sd = numpy.std(W, axis=-1)\n",
    "    print('SD:', sd.shape)\n",
    "\n",
    "    # Root mean square - 5*\n",
    "    rms = numpy.sqrt(numpy.mean(W, axis=-1))\n",
    "    print('RMS:', rms.shape)\n",
    "\n",
    "    # Root of sum of squares - 6*\n",
    "    rss = numpy.sqrt(numpy.sum(W, axis=-1))\n",
    "    print('RSS:', rss.shape)\n",
    "\n",
    "    # Kurtosis 7 *\n",
    "    kur = scipy.stats.kurtosis(W, axis=-1)\n",
    "    print('KUR:', kur.shape)\n",
    "\n",
    "    # Skewness 8\n",
    "    skw = scipy.stats.skew(W, axis=-1)\n",
    "    print('SKW:', skw.shape)\n",
    "    \n",
    "    final_features = list()\n",
    "    initial_features = [fmn, mx, mn, sd, rms, rss,]\n",
    "    for feature in (initial_features):\n",
    "        final_features.append(feature)\n",
    "    feature_array.append(numpy.concatenate(final_features, axis=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando o vetor de características X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = numpy.concatenate(final_features, axis=-1)\n",
    "print('Shape dos dados:', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaptação do vetor de labels y\n",
    "Temos que adaptar o vetor de labels para ficar do mesmo tamanho (mesma quantidade de linhas) que o vetor de dados X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = numpy.load('files/labels.npy')\n",
    "print('Shape original dos labels', y.shape)\n",
    "\n",
    "size = int(welch_array[0].shape[0] / y.shape[0])\n",
    "Y = numpy.concatenate([y for i in range(size)])\n",
    "print('Shape final dos labels', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for count in range(1000):\n",
    "    for kernel in ['linear', 'poly', 'rbf', 'sigmoid']:\n",
    "        for gamma in [10, 1, 0.1, 0.01, 0.001, 0.0001, 0.00001, 0.000001]:\n",
    "            for C in [0.01, 0.1, 1, 10, 100, 1000]:\n",
    "                results = []\n",
    "                for i in range(len(feature_array)):\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(\n",
    "                        feature_array[i], Y, train_size=0.7, shuffle=True)\n",
    "                    clf = SVC(kernel=kernel,gamma=0.0001, C=1)\n",
    "                    clf = clf.fit(X_train, y_train)\n",
    "                    res = clf.predict(X_test)\n",
    "                    results.append(res)\n",
    "                tot_hit = sum([1 for i in range(len(res)) if (numpy.argmax(numpy.bincount([n[0] for n in results]))) == y_test[i]])\n",
    "                acc = tot_hit / X_test.shape[0] * 100\n",
    "                if (acc >= 30):\n",
    "                    print('Kernel:{} | Gamma:{} e C:{} | Accuracy: {:.2f}% | {}/{}'.format(\n",
    "                        kernel, gamma, C, acc, tot_hit, X_test.shape[0])\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
